---
title: 'The Post-Developer Era'
date: '2025-04-28'
description: 'When OpenAI released GPT-4 back in March 2023, they kickstarted the AI revolution. The consensus online was that front-end development jobs would be totally eliminated within a year or two.Well, itâ€™s been more than two years since then, and I thought it was worth revisiting some of those early predictions, and seeing if we can glean any insights about where things are headed.'
---

Two years ago, in March 2023, I published a blog post called
**â€œThe End of Front-End Developmentâ€**. This was right after OpenAI released its
GPT-4 showcase, and the general reaction was that human software developers were
about to be made redundant, that software would soon be written exclusively by
machines.

I was skeptical of these claims, and in that blog post, I made the case for why I thought software development would still require humans for the foreseeable future. My hypothesis was that LLMs would augment human developers, not replace them.

At the time, the conventional wisdom on Twitter was that it would only be a few months before AI extinguished all demand for human front-end developers, maybe a year or two at most. Well, itâ€™s been over two years since then! So, were they right? Are we currently living in the â€œpost-developerâ€ era?

In this blog post, I want to take a fresh look at the current landscape, to see how things have changed, and to see if we can anticipate how things will continue to evolve. If youâ€™re an aspiring developer who is feeling anxious about your future career, my hope is that this post will give you some clarity. â¤ï¸

## Companies and AI usage

Over the past few years, companies have definitely been adopting AI tools more and more. For example, Forbes recently published an article titled _â€œAI Writes Over 25% Of Code At Googleâ€_.

The articleâ€™s title makes it sound like AI is doing 25% of the work and human developers are doing the other 75%, but thatâ€™s not actually whatâ€™s going on here. That title is misleading, in my opinion.

AI may be generating 25% of the code that gets committed at Google, but itâ€™s not acting independently. A skilled human developer is in the driverâ€™s seat, using their knowledge and experience to guide the AI, editing and shaping its output, and mixing it in with the code theyâ€™ve written. As far as I know, 100% of code at Google is still being created by developers. AI is just one of many tools they use to do their job.

In other words, itâ€™s not like product teams at Google have fired 25% of their developers and replaced them with pseudo-sentient AI robots who work autonomously and report directly to the product manager. I havenâ€™t heard of that happening at any large tech companies.

Now, there are startups who claim that their AIs can fully replace human developers. The most popular of these is **Devin**, a product created by Cognition and released a year ago, in March 2024. But when companies actually try to use it, they run into problems. For example, one team found that Devin could only complete 3 out of 20 assigned tasks, and it was ultimately more trouble than it was worth. They gave up after a month.

Hereâ€™s some of what their team had to say about it:

> Tasks it can do are those that are so small and well-defined that I may as well do them myself, faster, my way. Larger tasks where I might see time savings I think it will likely fail at. So no real niche where Iâ€™ll want to use it.  
> â€” **Johno Whitaker**

> I had initial excitement at how close it was because I felt I could tweak a few things. And then slowly got frustrated as I had to change more and more to end up at the point where I would have been better of [sic] starting from scratch and going step by step.  
> â€” **Isaac Flath**

These quotes arenâ€™t from AI skeptics, theyâ€™re from a technical team who work for an AI startup, trying the product with enthusiasm and in good faith. And their experience isnâ€™t unusual. Iâ€™ve read a handful of other real-world reports, and they all arrive at the same conclusion: this just doesnâ€™t work that well.

As far as I can tell, every AI success story still has skilled human developers as a necessary ingredient. So, I think itâ€™s safe to say that weâ€™re **not living in the post-developer era**.

## Drifting off-road

Over the past couple of years, Iâ€™ve experimented with a lot of AI tooling myself. A few months back, I switched to **Cursor**, an AI-powered IDE. Iâ€™ve been using its â€œagentâ€ mode with Claude Sonnet, and I have to admit, itâ€™s pretty remarkable. For certain kinds of tasks, I can give it some context and point it in the right direction, and it whips up a working solution on the first try.

Itâ€™s smart enough to catch and often fix TypeScript or lint errors, and there have even been a few times that Iâ€™ve learned something new, where the suggested solution was better than what I had planned to write, thanks to some cool API I wasnâ€™t aware of.

But itâ€™s not perfect. It does require guidance.

It feels a bit like driving on the highway with _â€œcruise controlâ€_: the car mostly goes where you point it, but you still need a hand on the steering wheel, keeping it steady. Otherwise, the car will slowly start to drift out of its lane. If you donâ€™t occasionally nudge it back on track, youâ€™ll wind up in a ditch.

And thatâ€™s kind of a problem for the â€œno more developersâ€ theory. If I didnâ€™t know how to code, I wouldnâ€™t notice the subtle-yet-critical issues with the modelâ€™s output. I wouldnâ€™t know how to course-correct, or even realize that course-correction was required!

Iâ€™ve heard from no-coders who have built projects using LLMs, and their experience is similar. They start off strong, but eventually reach a point where they just can't progress anymore, no matter how much they coax the AI. The code is a bewildering mess of non sequiturs, and beyond a certain point, no amount of duct tape can keep it together. It collapses under its own weight.

Also, there are lots of tasks that LLMs just arenâ€™t very good at. There have been times where Iâ€™ve spent a frustrating 10 minutes trying to get Claude to understand what I want before giving up and taking 5 minutes to build it myself. Iâ€™ve started developing an intuition for which tasks should be delegated to the AI, and which should be tackled the old-fashioned way.

On balance, LLMs do save me a significant amount of time. There have been cases where the LLM does 30 minutes of work for me in 30 seconds, and those cases are exhilarating. But, honestly, I think I still spend the majority of the time writing code myself.

Itâ€™s like a tag team wrestling match; when I hit a task that Claude would excel at, I tap out and let him tackle it. But Iâ€™m still the one writing the code most of the time, since itâ€™s faster or easier to do it myself.

## The current job market

When I wrote this post a couple of years back, it was a pretty tough time in the job market. Unfortunately, things are still pretty tough out there.

If youâ€™re a job-seeker, you know that there arenâ€™t as many high-quality job listings as there used to be, and the good ones get swamped with applications. Itâ€™s very hard to get an interview, let alone an offer.

But I donâ€™t think this is because companies are actually replacing their developers with autonomous AI agents. As Iâ€™ve shared, the real-world experiences Iâ€™ve read just donâ€™t support that hypothesis. So what gives? Why is it still so brutal out there?

I think there are a few factors:

- **Macro-economic stuff.** Interest rates are still relatively high, making it harder for startups to attract the funding they need to grow and hire developers. For several years now, the general economic sentiment has been that weâ€™re on the cusp of a recession.
- **Layoffs.** Big tech companies laid off hundreds of thousands of workers over the past couple of years, for a variety of reasons. This means that there are tons of highly-qualified devs out there, looking for work.
- **AI myths.** Some companies are still operating under the belief that AI really will make developers obsolete soon, and so theyâ€™re not hiring as aggressively as they otherwise would.

That last point is particularly frustrating. Companies are not hiring the developers they need because theyâ€™re convinced that AGI is right around the corner, and when that egg hatches, we wonâ€™t need human developers at all anymore. _â€œItâ€™ll be any week now,â€_ theyâ€™ve been saying for years. ğŸ˜…

## Looking forward

When I wrote **â€œThe End of Front-End Developmentâ€** back in 2023, I was trying to reach aspiring developers, folks who are in the process of learning to code, right at the start of their career. I saw how bleak everyoneâ€™s predictions were, and wanted to provide a counterweight to all of the FUD I saw online.

And for everything that has changed over the past two years, two things have stayed the same:

1. Companies still need human developers to build their products.
2. AI Evangelists are still claiming that, any day now, companies wonâ€™t need human developers to build their products.

If youâ€™re an aspiring developer, in college or a bootcamp or studying on your own, I still fully believe that there will be opportunities for you when youâ€™re ready to enter the workforce. It seems clear to me that weâ€™re still a long way from software development becoming fully automated. And once companies realize that AI works much better as a **developer enhancer** than as a **developer replacement**, I think theyâ€™ll stop sabotaging their own growth and start hiring at a more vigorous pace.

Thereâ€™s no doubt that AI models will continue to improve. It seems like every week, a new model gets released that breaks records on one benchmark or other. Most recently, it was Googleâ€™s turn when they announced **Gemini 2.0 Flash** and **2.5 Pro** models.

![chartImage](https://www.joshwcomeau.com/images/the-post-developer-era/chart-speed.png)
